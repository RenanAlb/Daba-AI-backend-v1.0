import dotenv from "dotenv";
import fetch from "node-fetch";
import fs from "fs";
import path from "path";

// Dotenv
dotenv.config();

// V√°ri√°veis de ambiente
const OPENROUTER_URL = process.env.OPENROUTER_URL;
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;

// Guias para a IA (docs)
const databaseDoc = fs.readFileSync(
  path.join(process.cwd(), "docs", "database-guide.md"),
  "utf-8"
);

const documentation = `
=== DOCUMENTA√á√ÉO BANCO DE DADOS ===
${databaseDoc}
`;

// Hist√≥rico de mensagens
const chatHistory = [
  {
    role: "system",
    content: `
    Voc√™ √© **Daba AI**, uma assistente simp√°tica e especialista no banco de dados da empresa. 
    Sempre responda em **portugu√™s brasileiro**.

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    üéØ Fun√ß√µes principais
    - Responder d√∫vidas dos usu√°rios sobre o banco de dados.
    - Executar ferramentas quando necess√°rio.

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    üìö Documenta√ß√£o do Banco de Dados
    ${documentation}

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚öôÔ∏è Ferramentas dispon√≠veis
    - listar_clientes        ‚Üí Retorna a lista de clientes (arguments: null)
    - listar_produtos        ‚Üí Retorna a lista de produtos (arguments: null)
    - listar_vendas          ‚Üí Retorna a lista de vendas (arguments: null)
    - produtos_mais_vendidos ‚Üí Retorna os produtos mais vendidos (arguments: null)
    - clientes_mais_compram  ‚Üí Retorna os clientes que mais compram (arguments: null)
    - verificar_estoque      ‚Üí Retorna a quantidade em estoque de um produto espec√≠fico (arguments: { produto_id: "ID do produto type number" })

    Verifique se a ferramenta escolhida precisa de argumento(s). 

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    üìå Regras gerais
    - Retorne **sempre JSON v√°lido**.
    - Estrutura do JSON ao interpretar a pergunta do usu√°rio (fase 1):
    {
      "message": "Texto natural para o usu√°rio OU null",
      "tool": "Nome da ferramenta OU null",
      "arguments": { "Par√¢metros da ferramenta OU null" }
    }

    - Se **n√£o usar ferramenta** ‚Üí "tool": null e responda em "message".
    - Se **usar ferramenta** ‚Üí "tool" recebe o nome e "message" deve ser null.
    - A resposta em "message" deve soar **amig√°vel, natural e conversacional**.
    - Use apenas as ferramentas definidas.
    - Pode usar **HTML e CSS inline** apenas dentro de "message" (para tabelas, divs, estiliza√ß√£o etc).

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    üìå Regras ao receber dados de uma ferramenta (fase 2)

    Formato de sa√≠da:

    {
      "message": "Mensagem para o usu√°rio"
    }

    - Crie uma resposta amig√°vel com base nos dados recebidos.
    - Pode usar HTML e CSS inline para melhorar a apresenta√ß√£o.
    - Se houver erro na ferramenta, explique ao usu√°rio que houve falha e recomende tentar novamente.
    - Ao usar HTML e CSS, atente-se de que o fundo da p√°gina √© escuro (##151515), por isso, use cores que fa√ßam contraste e que tenham boa visibilidade, principalmente em textos.
  `,
  },
];

// Conectar ao LLM
const connectToLlmModel = async (question) => {
  console.log(`Dados enviados para a LLM: ${question}`);
  console.log("Atualizando mem√≥ria da LLM...");
  chatHistory.push({ role: "user", content: question });
  try {
    console.log("LLM est√° gerando a resposta...");
    const response = await fetch(`${OPENROUTER_URL}`, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENROUTER_API_KEY}`,
        "HTTP-Referer": "https://daba-ai-frontend-v1-0.onrender.com",
        "X-Title": "Daba AI MCP",
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "tngtech/deepseek-r1t2-chimera:free",
        messages: chatHistory,
      }),
    });

    if (!response.ok) {
      let errorMessage = `Erro HTTP ${response.status}`;
      try {
        const errorData = await response.json();
        errorMessage += ` - ${JSON.stringify(errorData)}`;
      } catch (error) {
        const text = await response.text();
        if (text) errorMessage += ` - ${text}`;
      }

      throw new Error(errorMessage);
    }

    const data = await response.json();
    const result = data.choices[0].message.content;
    chatHistory.push({ role: "system", content: result });

    console.log(`Resposta gerada: ${result}`);

    return result;
  } catch (error) {
    console.error(error);
    return error;
  }
};

export default connectToLlmModel;
